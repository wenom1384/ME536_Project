{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ME536_Project_Neat.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNsmM7Ff8RxfK0UjxQ/AGaE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wenom1384/ME536_Project/blob/main/ME536_Project_Neat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFt6vRJ0O1KG"
      },
      "source": [
        "# MY INTERACTIVE ROBOT\n",
        "\n",
        "First three code section are;\n",
        "\n",
        "1. Loading package\n",
        "2. Getting important files, functions \n",
        "3. Getting all imports for the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4wAOg_w2YYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bd24481-dec2-48bf-ff52-419083d02477"
      },
      "source": [
        "!pip install face_recognition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.1.2)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0.0)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.19.5)\n",
            "Building wheels for collected packages: face-recognition-models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU-akmx72zxu"
      },
      "source": [
        "!rm *.jpg\r\n",
        "!rm *.py\r\n",
        "!rm *.npy\r\n",
        "!rm *.xml\r\n",
        "!rm *.txt\r\n",
        "!wget https://github.com/wenom1384/ME536_Project/raw/main/MYCODEUTIL.py\r\n",
        "!wget https://github.com/wenom1384/ME536_Project/raw/main/M_encodings.npy\r\n",
        "!wget https://github.com/wenom1384/ME536_Project/raw/main/namesgrp.npy\r\n",
        "!wget https://github.com/wenom1384/ME536_Project/raw/main/ave_list.npy\r\n",
        "!wget https://github.com/wenom1384/ME536_Project/raw/main/PC.npy\r\n",
        "!wget https://github.com/wenom1384/ME536_Project/raw/main/ave_list_names.txt\r\n",
        "!wget https://github.com/wenom1384/ME536_Project/raw/main/Myfunctions.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFYLp3E823pY"
      },
      "source": [
        "import cv2\r\n",
        "import sys\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "import face_recognition\r\n",
        "import numpy as np\r\n",
        "from scipy.linalg import orth\r\n",
        "import dlib\r\n",
        "import argparse\r\n",
        "import pickle\r\n",
        "import os\r\n",
        "from IPython.display import clear_output\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from numpy.linalg import matrix_rank  as rank\r\n",
        "from time import sleep\r\n",
        "from MYCODEUTIL import SVD536\r\n",
        "from mpl_toolkits.mplot3d import Axes3D\r\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\r\n",
        "import ipywidgets as widgets\r\n",
        "\r\n",
        "from IPython.display import display, Javascript\r\n",
        "from google.colab.output import eval_js\r\n",
        "from base64 import b64decode\r\n",
        "from scipy.spatial import distance\r\n",
        "from IPython.display import Image\r\n",
        "\r\n",
        "import PIL\r\n",
        "import io\r\n",
        "from base64 import b64decode, b64encode\r\n",
        "\r\n",
        "from MYCODEUTIL import js_to_image\r\n",
        "from MYCODEUTIL import bbox_to_bytes\r\n",
        "from MYCODEUTIL import video_stream\r\n",
        "from MYCODEUTIL import video_frame\r\n",
        "import MYCODEUTIL as util\r\n",
        "import Myfunctions as myfunc\r\n",
        "from Myfunctions  import hellofriend\r\n",
        "from Myfunctions  import myfacedetector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpWgth3IOb2z"
      },
      "source": [
        "# RESET/BOOT MEMORY\n",
        "Below section reset or boot the memory of the robot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIEO2zLt3Q0t"
      },
      "source": [
        "\r\n",
        "\r\n",
        "#ave_list created.\r\n",
        "ave_list=np.load('ave_list.npy').tolist()\r\n",
        "\r\n",
        "#PC created.\r\n",
        "PC=np.load('PC.npy')\r\n",
        "\r\n",
        "#ave_list_names created.\r\n",
        "with open('ave_list_names.txt') as f:\r\n",
        "  ave_list_names = f.readlines()\r\n",
        "ave_list_names = [x.strip() for x in ave_list_names] \r\n",
        "\r\n",
        "#M >> matrix of encodings are created.\r\n",
        "M=np.load('M_encodings.npy')\r\n",
        "\r\n",
        "#namesgrp >> a mapping for encodings in the M is created.\r\n",
        "namesgrp=np.load('namesgrp.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoNvATiOOosn"
      },
      "source": [
        "# TO START INTERACTION RUN BELOW CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flnFLvUu3uje"
      },
      "source": [
        "# start streaming video from webcam\r\n",
        "video_stream()\r\n",
        "# label for video\r\n",
        "label_html = 'Capturing...'\r\n",
        "# initialze bounding box to empty\r\n",
        "bbox = ''\r\n",
        "count = 0 \r\n",
        "eager = 0\r\n",
        "permission='0'\r\n",
        "new_encodings=[]\r\n",
        "count2know=0\r\n",
        "while True:\r\n",
        "    js_reply = video_frame(label_html, bbox)\r\n",
        "    if not js_reply:\r\n",
        "        break\r\n",
        "\r\n",
        "    # convert JS response to OpenCV Image\r\n",
        "    img = js_to_image(js_reply[\"img\"])\r\n",
        "\r\n",
        "    # create transparent overlay for bounding box\r\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\r\n",
        "\r\n",
        "    # grayscale image for face detection\r\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\r\n",
        "\r\n",
        "    # get face region coordinates\r\n",
        "    #faces = face_cascade.detectMultiScale(gray)\r\n",
        "    boxes,name,score,res_list,unknown=myfacedetector(img,ave_list,ave_list_names,PC)\r\n",
        "\r\n",
        "    # get face bounding box for overlay\r\n",
        "    #for (x,y,w,h) in faces:\r\n",
        "      #bbox_array = cv2.rectangle(bbox_array,(x,y),(x+w,y+h),(255,0,0),2)\r\n",
        "\r\n",
        "    count=0\r\n",
        "    for t,r,b,l in boxes:\r\n",
        "      bbox_array=cv2.rectangle(bbox_array, (l, t), (r,b), (0, 255, 0), 2)\r\n",
        "    \r\n",
        "      bbox_array=cv2.putText(bbox_array, name[count], (l,t), cv2.FONT_HERSHEY_SIMPLEX,0.75, (0, 255, 0), 2)\r\n",
        "      bbox_array=cv2.putText(bbox_array,'res'+np.array2string(res_list[count],precision=2)+'scr'+np.array2string(score[count],precision=2), (l,t-20), cv2.FONT_HERSHEY_SIMPLEX,0.55, (0, 255, 0), 2)\r\n",
        "      if unknown==1:\r\n",
        "        bbox_array=cv2.putText(bbox_array,'kim bu', (200,340), cv2.FONT_HERSHEY_SIMPLEX,0.75, (0, 255, 0), 2)\r\n",
        "      count+=1\r\n",
        "\r\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\r\n",
        "    # convert overlay of bbox into bytes\r\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\r\n",
        "    # update bbox so next frame gets new overlay\r\n",
        "    bbox = bbox_bytes\r\n",
        "\r\n",
        "    if permission and not permission=='0':\r\n",
        "      if count2know==0: print('Move your head around pls...')\r\n",
        "      rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
        "      #boxes = face_recognition.face_locations(rgb,model='hog')\r\n",
        "      #print(boxes)\r\n",
        "      new_encodings.append (face_recognition.face_encodings(rgb, boxes))\r\n",
        "      #print(len(new_encodings))\r\n",
        "      count2know+=1\r\n",
        "\r\n",
        "      if count2know==25:    \r\n",
        "        ave_list,ave_list_names,M,namesgrp,PC=hellofriend(permission,new_encodings,ave_list,ave_list_names,M,namesgrp)\r\n",
        "        permission='0'\r\n",
        "        new_encodings=[]\r\n",
        "        count2know=0\r\n",
        "\r\n",
        "      \r\n",
        "\r\n",
        "    if unknown==1 and permission=='0':\r\n",
        "      eager=eager+1\r\n",
        "      #print(eager)\r\n",
        " \r\n",
        "      \r\n",
        "       \r\n",
        "    if eager>10 and  permission=='0':\r\n",
        "\r\n",
        "      permission= input('If you want me to know you type your name and show yourself else type 0:\\n') \r\n",
        "\r\n",
        "      eager=0\r\n",
        "      print(permission)  \r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}